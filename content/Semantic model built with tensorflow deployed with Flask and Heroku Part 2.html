<!DOCTYPE html>
<html lang="en">
<head>
    <title>Semantic model built with tensorflow deployed with Flask and Heroku - Part 2 -</title>
    <meta name="slug" content="Semantic-model-built-with-tensorflow-deployed-with-Flask-and-Heroku-Part-2.html"/>
    <meta name="tags" content="Heroku" />
    <meta name="date" content="2018-03-10 22:28" />
    <meta name="category" content="Blog" />
    <meta name="authors" content="yumi" />
</head>
<body>

<div>
In the <a href="https://fairyonice.github.io/Semantic-model-built-with-tensorflow-deployed-with-Flask-and-Heroku-Part-2.html">previous blog</a>
I created a small semantic classification model that can be developed in Heroku.
The web application is hosted <a href="http://simple-text-prediction.herokuapp.com/">here in Heroku.</a>
In this short blog, I will briefly discuss my deployment process.

</div>

<br>

<div>
Despite that there are many public clouds that offers GPU instances,
such as
<a href ="https://aws.amazon.com/blogs/machine-learning/how-to-deploy-deep-learning-models-with-aws-lambda-and-tensorflow/">Amazon Web Service</a>,
<a href ="https://cloud.google.com/ml-engine/docs/deploying-models">Google Cloud</a>,
I decided to go with <a href ="https://www.heroku.com/">Heroku</a>, which does not offer GPU instances.
This is because Heroku is VERY easy to set up and it allows to host at most 5 applications FOR FREE.
</div>
<br>


<div>
In the <a href="https://fairyonice.github.io/Semantic-model-built-with-tensorflow-deployed-with-Flask-and-Heroku-Part-2.html">previous blog</a>,
I created a simple deep learning model for sentiment analysis using tensor-flow.
The model takes a tweet or short text as a sentence and return the likelihood of happiness.
My focus in the post was to simplify the model so that every calculation can be done within 30 seconds and the memory stays within 500MB.
</div>
<br>
<br>

<div>
<h4>Reference</h4>
    <ul>
        <li><a href= "/Semantic-model-built-with-tensorflow-deployed-with-Flask-and-Heroku-Part-1.html">Deep learning semantic model built with tensorflow deployed using Flask and Heroku Part 1 (Model Development)</a></li>
        <li><a href= "/Semantic-model-built-with-tensorflow-deployed-with-Flask-and-Heroku-Part-2.html">Deep learning semantic model built with tensorflow deployed using Flask and Heroku Part 2 (Deployment)</a></li>
        <li><a href="https://github.com/FairyOnIce/FairyOnIce.github.io">My Github repo containing Flask app</a></li>
    </ul>
</div>

<h1>Deployment</h1>
As my daily job focuses on model development, I do not have as much experience in deployment (and that is the reason why I am spending weekend to write this blog).
For someone like me, the learning curve may be too sharp if tring to learn everything at once. But if you take steps, every step is really easy.
Here are the steps I followed to deploy deep learning model in Heroku.

<h2>Step 0: Learn HTML</h2>
HTML stands for HyperText Markup Language.
Every webpage you look at is written in a language called HTML. You can think of HTML as the skeleton that gives every webpage structure.
If you do not know about HTML, <a href="https://www.codecademy.com/en/tracks/web">take a codeacademy's course about HTML & CSS (Free)</a> and try your best to go as far as possible
(until you get bored).


<h2>Step 1: Learn Flask</h2>
Flask is a micro web framework written in Python.
For a quick start, follow <a href ="https://pythonspot.com/flask-web-app-with-python/">this tutorial</a>,
it will let you create your first Flask web application and run it locally on your own computer in 10 minutes.


<h2>Step 2: Learn Jinja2</h2>
jinja2 is a popular templating engine for Python.
A web templating system combines a template with a certain data source to render dynamic web pages.
With jinja2, you can pass variable between your python script and html.

I recommend you to read <a href="http://jinja.pocoo.org/docs/dev/templates/">Template Designer Documentation.</a>
If you are too lazy to read it, here is the quick cheat sheet for its syntax:
<ul>
    <li>{% ... %} for Statements</li>
    <li>{{ ... }} for Expressions to print to the template output</li>
    <li>{# ... #} for Comments not included in the template output</li>
    <li>#  ... ## for Line Statements</li>
</ul>


<h2>Step 3: Learn Heroku</h2>
In Step 1, you already run the web application locally on your computer.
With a cloud service like Heroku, you are able to put your websites onto the public World Wide Web, with a publicly accessible URL.
<a href ="https://github.com/datademofun/heroku-basic-flask">This datademofun's github repo</a>
seems the simplest walkthrough on how to get set up with Heroku, its toolkit and then how to deploy a simple web application (for free) on the Heroku Cloud.

<h2>Step 4: Learn Heroku + deep learning</h2>
    My Flask app related codes are created by modifying <a href ="https://github.com/datademofun/heroku-basic-flask">datademofun's github repo</a>.
    While datademofun's Flask app only requires Flask and gunicorn, I need some additional python modules for pre processing data and to use deep learning functions.
    My requirements.txt contains:
    <script src="https://gist.github.com/FairyOnIce/24a0e70b48fbe892c122d706715f1a02.js"></script>

    You see that I have tensorflow as one of the requirements.txt but not Keras, my favorite deep learning framework.
    This is because I could not import Keras:


    As the Flask application with Keras worked locally in my computer but failed in Heroku,
    I believe that this was Hiroku related problem.
    More specifically, using Heroku, I could add it as one of the requirements.txt but when I add a line "import keras" in backend.py,
    the application failed with H13 error. What is the H13 error?
<br>
<p>Here is a quote from H13 - Connection closed without response.</p>
<blockquote cite="https://devcenter.heroku.com/articles/error-codes#h13-connection-closed-without-response">
    This error is thrown when a process in your web dyno accepts a connection, but then closes the socket without writing anything to it....
    One example where this might happen is when a Unicorn web server is configured with a timeout shorter than 30s
    and a request has not been processed by a worker before the timeout happens.
    In this case, Unicorn closes the connection before any data is written, resulting in an H13.
</blockquote>

    I solved this problem in very hacky way: I imported Keras through tensorflow. You can see this in my backend.py:
    <script src="https://gist.github.com/FairyOnIce/f9431ad1b71efc0825c74340ace02d15.js"></script>

    I agree this is not a very good solution but it was a quick go around!







</body>
</html>